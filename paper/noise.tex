\section{Hidden comunication by targeted reflections}

We will start from the paper \textit{Reconfigurable Intelligent Surface: Reflection Design Against Passive Eavesdropping} \cite{9328149}, explaining how to hide communication between two actors from eavesdroppers using Reconfigurable Intelligent Surfaces, then expanding it to multiple receiving users at the same time.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{imgs/problem-description.png}
  \caption{Setup}
  \label{fig:correlation_sk}
\end{figure}

In \cite{9328149}, the authors studied how to use RISs to allow communications between two users without LOS, while making the signal undeciphrable for eavesdroppers. We call $L$ the transmitter's antennas, $K$ the receiver's antennas, $M$ the eavesdropper's antenna, and $N$ the RIS reflecting elements. We assume $L \ge K \ge 2$.

We define $H \in \C^{NxL}$ the channel response from the transmitter to the RIS, $G \in \C^{KxN}$ the channel response from the RIS to the receiver, $P = diag\{p\} \in \C^{NxN}$ a diagonal matrix in which the $n$th diagonal element represents the reﬂection coefﬁcient of the $n$th unit at the RIS.

The objective is making the receiver's final signal $GPH$ a diagonal matrix, while making every possible eavesdropper's final signal a full matrix.

We will leave for now the technical details of why this would achieve secrecy for the legitimate users to the original paper, and will just focus on the mathematics behind the calculation. It is possible to read more in the paper \textit{Space shift keying modulation for MIMO channels} \cite{5165332}.

Our final objective will be to generalize these calculations to $J$ receving users and multiple RISs used in parallel and in sequence.

Formally, the condition we want to satisfy is:

\begin{equation}
  || [GPH]_{:,1:K} - [[GPH]_{:,1:K}]_{diag} || ^2 = 0
\end{equation}

Where $[GPH]_{:,1:K} \in \C^{KxK}$ denotes the first K columns of the matrix $GPH \in \C^{KxL}$.

Given

\begin{equation}
  W = \sum_{i,j = 1, i \ne j}^{K} (g_{j,:} \odot h_i^T)^H (g_{j,:} \odot h_i^T)
\end{equation}
\begin{equation}
  rank(W) = K(K-1), rank(W) - nullity(W) = N
\end{equation}
\begin{equation}
  nullity(W) = N - (K^2 - K)
\end{equation}

The formula (1) can be rewritten as

\begin{equation}Wp = 0\end{equation}

and the solutions of $p$ can be found in the null space of $W$. Using singular value decomposition (SVD), we can decompose

\begin{equation}
  W = R \Sigma V^H \footnote{An hermitian transpose of $V$ ($V^H$), means we fist transpose the matrix ($V \rightarrow V^T$), then take the conjugate of every element (so invert the sign of the immaginary part).}
\end{equation}

With SVD, we have $\Sigma = diag(\sigma) \in C^{NxN}$ a diagonal matrix. the first $rank(W) = K^2-K$ elements of $\sigma$ are non-zero, while the last $nullity(W) = N - (K^2-K)$ elements are zero. \footnote{\url{https://math.stackexchange.com/questions/1771013/how-is-the-null-space-related-to-singular-value-decomposition}}

Given a more generic $A \in \C^{mxn} = R' \Sigma' V'^H$, we have the column vectors of $R'$ being an orthonormal span of $C^m$, and the row vectors of $V'$ being an orthonormal span of $C^n$.

Suppose $A$ is an Hermitian matrix (meaning $A = A^H$). This will be useful later, as $W$ is also an Hermitian matrix by construction. Let's call $k$ the null space dimension of $A$, and ,by the property above, the null space dimension of $A^H$ too.

The last $k$ columns of $R'$ are a span of the null space
\begin{equation}
  N(A^H) = [r_{m-k}, ..., r_m ] \in \C^{mxk}
\end{equation}
while the last $k$ rows of $V'^H$ are a span of the null space
\begin{equation}
  N(A) = \begin{bmatrix} v'^H_{n-k} \\ ... \\ v'^H_n \end{bmatrix} \in \C^{kxn}
\end{equation}
Being $A$ an Hermitian matrix, the two null spaces are both solutions to $Ax = 0$.

Consider now $W \in C^{NxN}$. The paper in question uses equation (7) to find the solutions, since $W$ is hermitian and square. Taken $U \in \C ^ {Nx(N-(K^2 - K))}$ the last $N-(K^2 - K)$ columns of the left singular matrix $R$. $U \in N(W)$ for the explanation above. We then have

\begin{equation}WU = 0\end{equation}
\begin{equation}p = Uq\end{equation}
\begin{equation}WUq = 0\end{equation}

being true, and $q \in \C^{N-(K^2 - K)}$ can be a random vector.

\section{Expanding to multiple users}

In real life scenarios, we deal with more than two communicating actors. We want to expand the findings of this paper by having it support multiple RISs in series and multiple receivers from the same transmitter. Once we have those, we can generalize it to also have receivers getting signals from multiple indipendent reflections of RISs.

We will first, however, make some semplifications about the actors by having $L = K$ for all of them. We will still consider one transmitter, with $J \ge 1$ receivers.

\subsection{Reflecting to multiple users}

We consider the case where the transmitter wants to send the signal to $J$ receivers without LOS. The condition we want to satisfy is

\begin{equation}
  \forall j \in [1...J] \rightarrow || G_jPH - [G_jPH]_{diag} || ^2 = 0
\end{equation}

\begin{equation}
  \forall j \in [1...J] \rightarrow W_jp = 0
\end{equation}

\begin{equation}
  \begin{bmatrix}
    W_1  \\
    W_ 2 \\
    ...  \\\
    W_j
  \end{bmatrix}
  p = 0
\end{equation}

\begin{equation}
  \begin{bmatrix}
    W_1  \\
    W_ 2 \\
    ...  \\\
    W_j
  \end{bmatrix}
  = W \in \C ^ {JNxN}, W = R \Sigma V^H
\end{equation}

The problem we have now is that $W$ is not a square matrix anymore, so we cannot use the last $N - (K^2 - K)$ columns of $R$ to calculate the null space and $p$ with its linear combination. The null space would have dimension $N(W) \in \C^{JN x (N - (K^2 - K))}$, but we need $p \in C^N$.

We can, however, use the the last $N - (K^2 - K)$ rows of $V^H$, then apply again the hermitian transposition to get our desired solution. Remember that $N(W)$ can also be calculated using the left singular matrix. Since now $W$ is not a square matrix, so $W \ne W^H$,

\begin{equation}
  N(W) = \begin{bmatrix} v^H_{N - J(K^2 - K)} \\ ... \\ v^H_N \end{bmatrix} ^ H
\end{equation}

Take $U_1 \in \C ^ {N - J(K^2 - K) x N}$ the last $N - (K^2 - K)$ rows of $V^H$, and
\begin{equation}
  U = U_1^H \in \C ^ {N x N - J(K^2 - K)}
\end{equation}

We now can apply the same method as before

\begin{equation}p = Uq\end{equation}

\begin{equation}WU = 0\end{equation}

\begin{equation}WUq = 0\end{equation}

\subsection{RISs in parallel}

Given the previous property, it follows that we can use $M$ multiple RIS, each one reflecting the signal to $J$ multiple receivers. For the receiver $j \in [1, J]$, we have

\begin{equation}
  \sum_{m=1}^M G_j P_m H_m x = (\sum_{m=1}^M G_j P_m H_m) x =
\end{equation}

The sum of diagonal matrixes is still a diagonal matrix, so the property still holds.

\subsection{RISs in series}

We consider the case where the signal is bounced between $M$ RISs in this way:

\begin{equation}
  \text{Transmitter} \rightarrow \text{RIS 1} \rightarrow ... \rightarrow \text{RIS M} \rightarrow \text{Receiver}
\end{equation}

We call $C_i \in \C^{NxN}$ the channel gain between $P_i$ and $P_{i+1}$. We need to solve

\begin{equation}
  || GP_1C_1...P_MH - [GP_1C_1...P_MH]_{diag} || ^2 = 0
\end{equation}

We can generate $p_1, ..., p_{M-1}$ as random reflections, and calculate the last one based on the previous. An advantage we get is that eavesdroppers listening from a middle RIS will not be able to decipher the signal either. Given $r_i \in [0, 1]$ the absorption coefficient, and $\theta_i \in [0, 2\pi]$ the phase shift, we can choose them randomly for all RIS $p_m$ vectors, but the last one.

\begin{equation}
  \forall m \in [1, M-1] : p_m[i] = \eta * r_i * e^{j\theta_i}
\end{equation}

Given now

\begin{equation}
  G' = GP_1C_1...P_{M-1}C_{M-1} \in \C^{KxN}
\end{equation}

We can consider now the problem of solving

\begin{equation}
  || G'P_MH - [G'P_MH]_{diag} || ^2 = 0
\end{equation}

Which can be solved as before.
\footnote{It is also possible to set up randomly the last $M-1$ RIS and calculate the first one using $G$ and $H'=C_1P_2C_2...P_M$. The properties still holds.}
\footnote{Estimate the channel gains $G$ and $H$, based on \cite{8879620}, could be more difficult, given that we do not have full controll on $P=P_1C_1...P_M$ anymore. We can however estimate directly $G'$ by keeping the same random $P_1, ..., P_{M-1}$ in both the acknowlegdment round and the message trasmission round, and just modify $P_M$ after estimating $G'$ and $H$ to correctly deliver the message.}

If we have multiple $G_j$, it will be enough to calculate all the $G'_j$ and proceed as before, allowing us to combine these properties in more complicated scenarios.
